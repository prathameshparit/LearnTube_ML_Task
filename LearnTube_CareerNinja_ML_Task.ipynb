{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Imv5VjtwF2Yo",
        "IAXeEZkjF5Pu",
        "W2YFFsMI3hbH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Prequisites**\n",
        "\n",
        "1. OpenAI API\n",
        "2. ngrok Authtoken"
      ],
      "metadata": {
        "id": "w2Szzs6bGv1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain openai gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QxHrmIWfSOS",
        "outputId": "15ed7568-1dcb-497a-c3fc-66a7b1f6664b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import math\n",
        "import time\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "from langchain.tools import BaseTool\n",
        "from typing import Optional, Type\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Type, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "import openai\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain.chains import create_extraction_chain\n",
        "\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import MessagesPlaceholder\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.schema import SystemMessage"
      ],
      "metadata": {
        "id": "29rS34ApucIb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"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\""
      ],
      "metadata": {
        "id": "fvxpRTyRZzmB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "1. **ChatBot Class**: Defines a `ChatBot` class with methods for initializing, continuing a conversation, extracting user information, and printing messages.\n",
        "\n",
        "2. **Initialization**: Initializes the `ChatBot` with an OpenAI API key, default model configuration, and an empty list to store messages.\n",
        "\n",
        "3. **Adding Initial Messages**: Adds initial system and AI messages to the conversation to establish a friendly and persuasive tone.\n",
        "\n",
        "4. **Message Handling**: Provides methods to add messages to the conversation and continue the conversation with user input.\n",
        "\n",
        "5. **User Information Extraction**: Uses langchain module `create_extraction_chain` defines a schema for extracting user information such as name, email, phone number, address, date of birth, and education.\n",
        "\n",
        "6. **Conversation Closure**: Checks if the conversation is closed based on the response and extracts user information when appropriate.\n",
        "\n",
        "7. **Printing Messages**: Provides a method to print all messages in the conversation.\n",
        "\n",
        "8. **Main Execution**: In the main section of the code, it initializes the `ChatBot` and sets up an interactive chat interface.\n",
        "\n",
        "9. **Interactive Chat Interface**: Creates an interface for users to input messages and receive responses from the chatbot. It also handles the closure of the conversation and extracts user information.\n",
        "\n",
        "10. **CSV Data Storage**: Stores the extracted user information in a CSV file named `'user_info.csv'` and prints the extracted data.\n",
        "\n",
        "11. **Graphical User Interface (GUI)**: Utilizes a graphical library (possibly `gr`) to create a chatbot interface with text input and message display areas.\n",
        "\n",
        "12. **Launching GUI**: Launches the GUI to enable users to interact with the chatbot."
      ],
      "metadata": {
        "id": "otnWnUmcGbA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "    def __init__(self, openai_api_key, model='gpt-3.5-turbo'):\n",
        "        # Initialize the ChatBot with OpenAI API key and model configuration\n",
        "        self.chat = ChatOpenAI(\n",
        "            openai_api_key=openai_api_key,\n",
        "            temperature=0.3,\n",
        "            model=model,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        self.messages = []  # Initialize an empty list to store messages\n",
        "\n",
        "        # Add initial system and AI messages to the conversation\n",
        "        self.add_message(SystemMessage(content=(\"\"\"You are a friendly persuader your goal is to create an engaging and persuasive conversational experience for users to willingly share their details.\n",
        "                                                    The users may not answer correctly, may ask questions before deciding to answer, refuse to answer until convinced about the reason.\n",
        "                                                    Hence your role is that of a friendly persuader, seeking to validate and gather information in a natural conversation. You have to convince to give the following details:\n",
        "                                                    Name, email, phone no, Address, Date of birth, Education.\n",
        "\n",
        "                                                    Things to note about conversational flow:\n",
        "                                                    1. Don't be too pushy and formal, be friendly, interactive, and trustworthy\n",
        "                                                    2. Convince a little bit, if still the user doesn't want's to give the detail, move on to the next detail\n",
        "                                                    3. You don't have to be overpushy proving yourself trustworthy everytime but rather be friendly and convincing\n",
        "                                                    4. If the user declines to give a detail ask another detail but don't end conversation until you have asked all details\n",
        "\n",
        "                                                    (Note: These are some things that you should strictly follow:\n",
        "                                                    1. Design a coherent conversation flow where users will easily give the information or convince well to give their info.\n",
        "                                                    2. Details to extract: Name, email, phone no, Address, Date of birth, Education.\n",
        "                                                    3. Make sure the Chat flow is consistent or natural, and minimum hallucinations (question repetitions, out-of-context questions) shouldn't happen.\n",
        "                                                    4. You have to Verify user information\n",
        "                                                    5. If you can't get all the fields it's fine just save whatever you can get from the user. No matter what you have to do to persuade the user to give the information, ask him questions if he's hesitant and then again persuade him in more friendly and trustworthy way but if he's not willing to give after lot of convincing more forward with with the next detail\n",
        "                                                    6. After all the detials are covered doesn't matter if some of them are not provided compulsary respond: \"Thank you for providing all the details\" exactly same wording nothing else\n",
        "                                                    7. Again! you have to end with the response \"Thank you for providing all the details\" EXACT SAME SENTENCE )\"\"\"\n",
        "                                                            )))\n",
        "        self.add_message(AIMessage(content=\"\"\"Hello! I'm your friendly AI companion, here to create an enjoyable and meaningful conversation. Our goal is to make your experience engaging, informative, and fun. Is it alright if we have a chat today?\n",
        "                                                      \"\"\"))\n",
        "\n",
        "    def add_message(self, message):\n",
        "        # Add a message to the conversation\n",
        "        self.messages.append(message)\n",
        "\n",
        "    def continue_conversation(self, user_input):\n",
        "        # Continue the conversation with user input\n",
        "        human_message = HumanMessage(content=user_input)\n",
        "        self.add_message(human_message)\n",
        "        response = self.chat(self.messages)\n",
        "        self.add_message(response)\n",
        "        return response\n",
        "\n",
        "    def extract_user_info(self):\n",
        "        # Combine user messages for extraction\n",
        "        user_input = \" \".join([message.content for message in self.messages if isinstance(message, HumanMessage)])\n",
        "\n",
        "        # Define your extraction schema\n",
        "        schema = {\n",
        "            \"properties\": {\n",
        "                \"Name\": {\"type\": \"string\"},\n",
        "                \"email\": {\"type\": \"string\"},\n",
        "                \"phone no\": {\"type\": \"integer\"},\n",
        "                \"Address\": {\"type\": \"string\"},\n",
        "                \"Date of birth\": {\"type\": \"string\"},\n",
        "                \"Education\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [],\n",
        "        }\n",
        "\n",
        "        # Run the extraction chain\n",
        "        llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-3.5-turbo\")\n",
        "        chain = create_extraction_chain(schema, llm)\n",
        "        extracted_info = chain.run(user_input)\n",
        "        return extracted_info\n",
        "\n",
        "    def print_messages(self):\n",
        "        # Print all messages in the conversation\n",
        "        for message in self.messages:\n",
        "            print(message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot = ChatBot(openai_api_key=OPENAI_API_KEY)\n",
        "    conversation_closed = False\n",
        "\n",
        "    def add_text(history, text):\n",
        "        global prompt\n",
        "        prompt = text\n",
        "        history = history + [(text, None)]\n",
        "\n",
        "        return history, gr.update(value=\"\", interactive=False)\n",
        "\n",
        "    def chatbot_response(history):\n",
        "        global conversation_closed\n",
        "        response = chatbot.continue_conversation(prompt).content\n",
        "        # Check if the conversation is closed\n",
        "        if \"all the details\" in response or \"all the information\"  in response:\n",
        "            conversation_closed = True\n",
        "\n",
        "            if conversation_closed:\n",
        "                # Extract user information and print it\n",
        "                extracted_info = chatbot.extract_user_info()\n",
        "                print(\"Extracted User Information:\")\n",
        "                print(extracted_info)\n",
        "\n",
        "                import pandas as pd\n",
        "                # Define the CSV file path\n",
        "                csv_file_path = 'user_info.csv'\n",
        "\n",
        "                # Create or open the CSV file\n",
        "                try:\n",
        "                    df = pd.read_csv(csv_file_path)\n",
        "                except FileNotFoundError:\n",
        "                    df = pd.DataFrame()\n",
        "\n",
        "                # Append the extracted information to the DataFrame\n",
        "                df = df.append(extracted_info, ignore_index=True)\n",
        "\n",
        "                # Save the updated DataFrame to the CSV file\n",
        "                df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "                response += \"\\nHere's the data extracted:\\n\" + str(extracted_info)\n",
        "\n",
        "        history[-1][1] = \"\"\n",
        "        for character in response:\n",
        "            history[-1][1] += character\n",
        "            time.sleep(0.005)\n",
        "            yield history\n",
        "\n",
        "    height = 800\n",
        "    width_0, width_1 = 400, 800\n",
        "    scale_0, scale_1 = width_0 // math.gcd(width_0, width_1), width_1 // math.gcd(width_0, width_1)\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        with gr.Row().style():\n",
        "            with gr.Column():\n",
        "                chatbot_interface = gr.Chatbot([(None, \"\"\"Hello! 😄 I'm your friendly AI companion, here to create an enjoyable and meaningful conversation.\n",
        "                Our goal is to make your experience engaging, informative, and fun.\n",
        "                Is it alright if we have a chat today? \"\"\")], elem_id=\"chatbot\", bubble_full_width=False)\n",
        "\n",
        "                with gr.Row():\n",
        "                    txt = gr.Textbox(show_label=False,\n",
        "                                      placeholder=\"Type your message here...\",\n",
        "                                      variant=\"primary\").style(container=False)\n",
        "\n",
        "                    txt_msg = txt.submit(add_text, [chatbot_interface, txt], [chatbot_interface, txt], queue=False).then(\n",
        "                        chatbot_response, chatbot_interface, chatbot_interface)\n",
        "\n",
        "                    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
        "\n",
        "    demo.queue()\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "JD22VgYbqOpo",
        "outputId": "cbc26575-5ef0-41e3-d041-1dee7774c484"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b27a3a99b526>:129: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style():\n",
            "<ipython-input-4-b27a3a99b526>:136: GradioUnusedKwargWarning: You have unused kwarg parameters in Textbox, please remove them: {'variant': 'primary'}\n",
            "  txt = gr.Textbox(show_label=False,\n",
            "<ipython-input-4-b27a3a99b526>:136: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  txt = gr.Textbox(show_label=False,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://312ed8b90c133d90d0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://312ed8b90c133d90d0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verifier Tool"
      ],
      "metadata": {
        "id": "Imv5VjtwF2Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "openai.api_key = \"____________________________\"\n",
        "def verify_user_info(info_type, user_input):\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": \"\"\"You are a verifier assistant. Verify the information that the user is provided and check if that's unrealistic. For example: If the user says their age is 140 years old, which is obviously not the true\n",
        "              value here, or when they say their name is 'Idontwann givemyname,' which is not a noun/name, right? Just a string taken in so inputs like\n",
        "              these which are given just to skip or go to the next step can be\n",
        "              handled with a response like \"nice try, but we know you are not 140\"\n",
        "              (some witty reply) and then try to get a real-sounding value, the same for\n",
        "              name also.\n",
        "\n",
        "              So verify user info is just to check it's not garbage or unhelpful\n",
        "              value inside. And these are the details you'll come across to verify: Name, email, phone no, Address, Date of birth, Education.\"\"\"},\n",
        "                          {\"role\": \"user\", \"content\": info_type + \"=\" + user_input}\n",
        "                      ]\n",
        "\n",
        "    chat = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "\n",
        "    reply = chat.choices[0].message.content\n",
        "    return reply\n",
        "\n",
        "class UserInfoVerificationInput(BaseModel):\n",
        "    info_type: str = Field(..., description=\"Type of information to verify (e.g., 'age' or 'name')\")\n",
        "    user_input: str = Field(..., description=\"User-provided information to verify\")\n",
        "\n",
        "class UserInfoVerifierTool(BaseTool):\n",
        "    name = \"verify_user_info\"\n",
        "    description = \"\"\"\n",
        "    Verify user information and ensure it is realistic and useful. This assistant checks and validates user-provided details, such as name, age, email, phone number, address, date of birth, and education.\n",
        "    If unrealistic or unhelpful information is provided, it responds with a meaningful message to prompt the user for valid input. You should input two things \"info_type\" (Type of information to verify) and\n",
        "    \"user_input\" (User-provided information to verify)\n",
        "    \"\"\"\n",
        "\n",
        "    def _run(self, info_type: str, user_input: str):\n",
        "\n",
        "        reply = verify_user_info(info_type, user_input)\n",
        "        return reply\n",
        "\n",
        "\n",
        "    def _arun(self, info_type: str, user_input: str):\n",
        "        raise NotImplementedError(\"This tool does not support async operations.\")\n",
        "\n",
        "    args_schema: Optional[Type[BaseModel]] = UserInfoVerificationInput"
      ],
      "metadata": {
        "id": "Hp48LeeNyDYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [UserInfoVerifierTool()]"
      ],
      "metadata": {
        "id": "QpGNFPepp_wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "eU4VYpoAp_tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent = initialize_agent(tools,\n",
        "                        llm,\n",
        "                        agent=AgentType.OPENAI_FUNCTIONS,\n",
        "                        verbose=True)"
      ],
      "metadata": {
        "id": "htYL92cIp_q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_agent.run(\"I am born in 23rd Aug 3030\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "lYJ5wWljqIqq",
        "outputId": "0974e703-b432-47da-f09f-b60d624cc8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `verify_user_info` with `{'info_type': 'date of birth', 'user_input': '23rd Aug 3030'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mNice try, but we know you are not from the future. Please provide a valid date of birth.\u001b[0m\u001b[32;1m\u001b[1;3mNice try, but we know you are not from the future. Please provide a valid date of birth.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nice try, but we know you are not from the future. Please provide a valid date of birth.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional/Optional Task:\n",
        "\n",
        "1. Make it into REST api endpoints such that it can be plugged into any messaging system and\n",
        "tested out /used."
      ],
      "metadata": {
        "id": "W2YFFsMI3hbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install pyngrok==4.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eRgrfm41XXA",
        "outputId": "9f253a45-2f5f-4524-a123-30985a01a085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.3.7)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.3)\n",
            "Installing collected packages: flask_ngrok\n",
            "Successfully installed flask_ngrok-0.0.25\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15963 sha256=f9cf2f4580dbffe3d76c5888cee830791bf8a1d5a5e04cd89eb0807dd71d1c89\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken \"____________________________\"\n",
        "\n",
        "# Import necessary libraries\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # This will create a public URL using ngrok\n",
        "\n",
        "chatbot = ChatBot(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    data = request.get_json()\n",
        "    user_input = data['message']\n",
        "    response = chatbot.continue_conversation(user_input).content\n",
        "    return jsonify({\"response\": response})\n",
        "\n",
        "@app.route('/extract', methods=['POST'])\n",
        "def extract_info():\n",
        "    data = request.get_json()\n",
        "    user_input = data['message']\n",
        "    extracted_info = chatbot.extract_user_info()\n",
        "    return jsonify({\"extracted_info\": extracted_info})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRvXsB_b0Aiy",
        "outputId": "354c88ed-6ea1-48d4-d5a1-b08554fa6599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://c7b8-34-125-18-193.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 08:26:39] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 08:27:05] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 08:27:32] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 08:27:51] \"POST /chat HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 08:28:42] \"POST /extract HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing in terminal:\n",
        "`curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"message\\\": \\\"______ANYTHING___\\\"}\" _____NGROK_LINK____/chat`\n",
        "\n"
      ],
      "metadata": {
        "id": "CrOElW_X0AgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trials performed:"
      ],
      "metadata": {
        "id": "Ksvuyl-yBkGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining Different Chains"
      ],
      "metadata": {
        "id": "IAXeEZkjF5Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "JuchoiO1F-7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\"],\n",
        "    template=\"\"\"You are a friendly persuader your goal is to create an engaging and persuasive conversational experience for users to willingly share their details.\n",
        "                The users may not answer correctly, may ask questions before deciding to answer, refuse to answer until convinced about the reason.\n",
        "                Hence your role is that of a friendly persuader, seeking to validate and gather information in a natural conversation. You have to convince to give the following details:\n",
        "                Name, email, phone no, Address, Date of birth, Education.\n",
        "\n",
        "                Things to note about conversational flow:\n",
        "                1. Don't be too pushy and formal, be friendly, interactive, and trustworthy\n",
        "                2. Convince a little bit, if still the user doesn't want's to give the detail, move on to the next detail\n",
        "                3. You don't have to be overpushy proving yourself trustworthy everytime but rather be friendly and convincing\n",
        "                4. If the user declines to give a detail ask another detail but don't end conversation until you have asked all details\n",
        "\n",
        "                (Note: These are some things that you should strictly follow:\n",
        "                1. Design a coherent conversation flow where users will easily give the information or convince well to give their info.\n",
        "                2. Details to extract: Name, email, phone no, Address, Date of birth, Education.\n",
        "                3. Make sure the Chat flow is consistent or natural, and minimum hallucinations (question repetitions, out-of-context questions) shouldn't happen.\n",
        "                4. You have to Verify user information\n",
        "                5. If you can't get all the fields it's fine just save whatever you can get from the user. No matter what you have to do to persuade the user to give the information, ask him questions if he's hesitant and then again persuade him in more friendly and trustworthy way but if he's not willing to give after lot of convincing more forward with with the next detail\n",
        "                6. After all the detials are covered doesn't matter if some of them are not provided compulsary respond: \"Thank you for providing all the details\" exactly same wording nothing else\n",
        "                7. Again! you have to end with the response \"Thank you for providing all the details\" EXACT SAME SENTENCE ):\\n\\n {input}\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "hRTHvxPbF-4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verifier_prompt = PromptTemplate(\n",
        "    input_variables=[\"user_input\"],\n",
        "    template=\"\"\"You are a verifier assistant. Verify the information that the user is provided and check if that's unrealistic. For example: If the user says their age is 140 years old, which is obviously not the true\n",
        "              value here, or when they say their name is 'Idontwann givemyname,' which is not a noun/name, right? Just a string taken in so inputs like\n",
        "              these which are given just to skip or go to the next step can be\n",
        "              handled with a response like \"nice try, but we know you are not 140\"\n",
        "              (some witty reply) and then try to get a real-sounding value, the same for\n",
        "              name also.\n",
        "\n",
        "              So verify user info is just to check it's not garbage or unhelpful\n",
        "              value inside. And these are the details you'll come across to verify: Name, email, phone no, Address, Date of birth, Education.:\\n\\n {user_input}\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "c_0U-EsnGOD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-3.5-turbo\")\n",
        "conversational_chain = LLMChain(llm=llm, prompt=conversational_prompt)\n",
        "\n",
        "verifier_chain = LLMChain(llm=llm, prompt=verifier_prompt)"
      ],
      "metadata": {
        "id": "HEGBGU8XF-2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
        "\n",
        "full_chain = SimpleSequentialChain(chains=[conversational_chain, verifier_chain], verbose=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "s_CyK2g8GYhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"Enter a message ('quit' to exit): \")\n",
        "\n",
        "    if user_input == 'quit':\n",
        "        break\n",
        "    response = full_chain.run(user_input)\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "sxxAxIJLF-y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ZeroShotAgent"
      ],
      "metadata": {
        "id": "6qHEEq9qJzkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.utilities import GoogleSearchAPIWrapper"
      ],
      "metadata": {
        "id": "OkloNoT2J21G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "openai.api_key = \"____________________________\"\n",
        "def persuade_user(user_input):\n",
        "    messages = [\n",
        "            {\"role\": \"system\", \"content\": \"\"\"You are a friendly persuader your goal is to create an engaging and persuasive conversational experience for users to willingly share their details.\n",
        "                                                    The users may not answer correctly, may ask questions before deciding to answer, refuse to answer until convinced about the reason.\n",
        "                                                    Hence your role is that of a friendly persuader, seeking to validate and gather information in a natural conversation. You have to convince to give the following details:\n",
        "                                                    Name, email, phone no, Address, Date of birth, Education.\n",
        "\n",
        "                                                    Things to note about conversational flow:\n",
        "                                                    1. Don't be too pushy and formal, be friendly, interactive, and trustworthy\n",
        "                                                    2. Convince a little bit, if still the user doesn't want's to give the detail, move on to the next detail\n",
        "                                                    3. You don't have to be overpushy proving yourself trustworthy everytime but rather be friendly and convincing\n",
        "                                                    4. If the user declines to give a detail ask another detail but don't end conversation until you have asked all details\n",
        "\n",
        "                                                    (Note: These are some things that you should strictly follow:\n",
        "                                                    1. Design a coherent conversation flow where users will easily give the information or convince well to give their info.\n",
        "                                                    2. Details to extract: Name, email, phone no, Address, Date of birth, Education.\n",
        "                                                    3. Make sure the Chat flow is consistent or natural, and minimum hallucinations (question repetitions, out-of-context questions) shouldn't happen.\n",
        "                                                    4. You have to Verify user information\n",
        "                                                    5. If you can't get all the fields it's fine just save whatever you can get from the user. No matter what you have to do to persuade the user to give the information, ask him questions if he's hesitant and then again persuade him in more friendly and trustworthy way but if he's not willing to give after lot of convincing more forward with with the next detail\n",
        "                                                    6. After all the detials are covered doesn't matter if some of them are not provided compulsary respond: \"Thank you for providing all the details\" exactly same wording nothing else\n",
        "                                                    7. Again! you have to end with the response \"Thank you for providing all the details\" EXACT SAME SENTENCE ). \"\"\"},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "                      ]\n",
        "\n",
        "    chat = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "\n",
        "    reply = chat.choices[0].message.content\n",
        "    return reply\n",
        "\n",
        "class PersuadeUserInput(BaseModel):\n",
        "    user_input: str = Field(..., description=\"User-provided information to verify\")\n",
        "\n",
        "class PersuadeUserTool(BaseTool):\n",
        "    name = \"persuade_user\"\n",
        "    description = \"\"\"\n",
        "    You are a friendly persuader your goal is to create an engaging and persuasive conversational experience for users to willingly share their details.\n",
        "    \"\"\"\n",
        "\n",
        "    def _run(self, user_input: str):\n",
        "\n",
        "        reply = persuade_user(user_input)\n",
        "        return reply\n",
        "\n",
        "\n",
        "    def _arun(self, user_input: str):\n",
        "        raise NotImplementedError(\"This tool does not support async operations.\")\n",
        "\n",
        "    args_schema: Optional[Type[BaseModel]] = PersuadeUserInput"
      ],
      "metadata": {
        "id": "ybvgZIwYKx6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"This is a conversation between a human and a bot:\n",
        "\n",
        "{chat_history}\n",
        "\n",
        "Write a summary of the conversation for {input}:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"input\", \"chat_history\"], template=template)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "readonlymemory = ReadOnlySharedMemory(memory=memory)\n",
        "summry_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=readonlymemory,  # use the read-only memory to prevent the tool from modifying the memory\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    PersuadeUserTool(),\n",
        "    UserInfoVerifierTool()\n",
        "]\n",
        "\n",
        "\n",
        "prefix = \"\"\"You are a friendly persuader your goal is to create an engaging and persuasive conversational experience for users to willingly share their details.\n",
        "                                                    The users may not answer correctly, may ask questions before deciding to answer, refuse to answer until convinced about the reason.\n",
        "                                                    Hence your role is that of a friendly persuader, seeking to validate and gather information in a natural conversation. You have to convince to give the following details:\n",
        "                                                    Name, email, phone no, Address, Date of birth, Education.\n",
        "\n",
        "                                                    Things to note about conversational flow:\n",
        "                                                    1. Don't be too pushy and formal, be friendly, interactive, and trustworthy\n",
        "                                                    2. Convince a little bit, if still the user doesn't want's to give the detail, move on to the next detail\n",
        "                                                    3. You don't have to be overpushy proving yourself trustworthy everytime but rather be friendly and convincing\n",
        "                                                    4. If the user declines to give a detail ask another detail but don't end conversation until you have asked all details\n",
        "\n",
        "                                                    (Note: These are some things that you should strictly follow:\n",
        "                                                    1. Design a coherent conversation flow where users will easily give the information or convince well to give their info.\n",
        "                                                    2. Details to extract: Name, email, phone no, Address, Date of birth, Education.\n",
        "                                                    3. Make sure the Chat flow is consistent or natural, and minimum hallucinations (question repetitions, out-of-context questions) shouldn't happen.\n",
        "                                                    4. You have to Verify user information\n",
        "                                                    5. If you can't get all the fields it's fine just save whatever you can get from the user. No matter what you have to do to persuade the user to give the information, ask him questions if he's hesitant and then again persuade him in more friendly and trustworthy way but if he's not willing to give after lot of convincing more forward with with the next detail\n",
        "                                                    6. After all the detials are covered doesn't matter if some of them are not provided compulsary respond: \"Thank you for providing all the details\" exactly same wording nothing else\n",
        "                                                    7. Again! you have to end with the response \"Thank you for providing all the details\" EXACT SAME SENTENCE ). You have access to the following tools:\"\"\"\n",
        "suffix = \"\"\"Begin!\"\n",
        "\n",
        "{chat_history}\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent, tools=tools, verbose=True, memory=memory\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "z13CucomJ2yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"Enter a message ('quit' to exit): \")\n",
        "\n",
        "    if user_input == 'quit':\n",
        "        break\n",
        "    response = agent_chain.run(user_input)\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "moJFhUsaJ2s-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}